# 为什么机器学习解决网络安全问题总是失败：机器学习不是万能灵药

本文的所有内容与作者的日常工作无关，其观点也仅代表作者个人意见，与作者的雇主无关。

这是本系列文章的最后一篇，我们从问题求解的角度来讨论机器学习解决网络安全问题时失败的另一个原因，机器学习在解决某些问题时，有时是方法的用法不对，有时是方法和问题根本不适合。

* 深度学习不是一切
* 机器学习仅是人工智能领域之一
* “你是否考虑过更简单的方法？”

## 深度学习不是一切

我们见到很多谈机器学习就必谈深度学习的场景。深度神经网络在图像文本等领域表现了深层网络对特征表示学习（representation learning）的强大优势，加之由神经网络带来的迁移学习（transfer learning）在解决多个问题时的神奇效果，它对解决网络安全问题的思路带来不小的冲击，大家都想试试看网络安全问题能不能因此受益。不过”天下没有免费午餐“，神奇的深度学习用其适用性作为代价换来了部分问题的解决，过去的几年里涌现的失败案例给我们总结了一些经验。

特征表示对网络结构的选择需要建构在对问题和模型的理解上。网络安全领域里序列模型似乎最为受宠，RNN/LSTM 因为其简单的开源实现而备受关注，于是我们在各个问题上都可以看到它的身影，比如之前提到的 LSTM 预测 DGA 算法的多个工作，其本意是寻找模型拟合 DGA 背后的伪随机数生成器（PRNG）。抛开 DGA 可能使用异或、位移、素数变换等多种不同的 PRNG 组合导致 LSTM 等浅层网络很难有效完整拟合并解释，LSTM 对初始状态的记忆和依赖也会对 PRNG 的拟合效果适得其反。Mostafa Hassan “Cracking Random Number Generators using Machine Learning – Part 1: xorshift128” `*` 抛开 LSTM 而只设计使用了 Dense Network 即可对基于 `xorshift128` 的 PRNG 做到很好的拟合，文中也对比了 LSTM + Dense Network 的实验效果，并对拟合结果做了了分析，有兴趣的小伙伴可以继续阅读。

机器学习行业有一句俗话，“垃圾进，垃圾出”。网络安全问题有多样的输入，而深度神经网络并不是关于特征组合的通用人工智能，它需要该网络结构可以处置的合理的输入才可以通过表示学习得到特征。一个典型的例子是之前提到的 `malconv` ，它试图借用图像处理的方法，通过输入二进制文件的原始字节码到简单的卷积层并抽取和归纳基础特征，而简单卷积并不足以感知编译器对字节码的组合，其结果为该网络仅学习到文件头签名等特征而非与恶意行为相关的函数调用特征。在 Joshua Saxe with Hillary Sanders “Malware Data Science: Attack Detection and Attribution“`*` 这本书里分析了 opcode 和基于 opcode 的相关建模工作，指令跳转或者函数输出表等作为模型的输入可以更好的支持恶意软件的检测模型。

网络安全问题有较强的对抗和动态性，它需要模型自带一些基本的假设去处理未知情况并证实其预测理由，而深度神经网络缺乏归纳偏置（Inductive bias）`*`，它对未知情况的预测很不确定也不好解释，这导致了使用深度模型时的“黑盒”困扰。如果是线性回归做拟合，我们可以观测其 Y 值与以 X 向量为参数的线性函数，如果是 Logistic 回归，我们可以观察其超平面对正负样本的切分情况，这些归纳偏置都可以证实（justify）模型的预测，而深度神经网络只能表明 Y 是 X 向量的某种非线性函数，该函数与数据增强、网络结构、激活函数、归一化等各种在训练过程中加入的约束条件有关，这导致在实际使用中很难证实预测结果的有效性，加之网络安全问题往往需要较强的领域知识做较为昂贵的验证，最近的一些增强模型可解释性的工作对此也仅有有限的缓解。一个有趣的例子是 SpamAssassin 这个垃圾邮件检测的开源项目，它在历史上出现过一个神奇的 bug，会把所有 2010 年之后的邮件全部判别为垃圾邮件。因为在垃圾邮件这种强对抗场景里攻击方总在变换不同花样，它的 Bayesian 判别器按照年份调整了每个特征的权重，这本是一个合理的做法，但是训练集里没有 2010年之后的数据，该判别器就本着宁可错杀也不放过的偏置将所有未知的邮件全部判断为垃圾邮件。当然，SpamAssassin 的模型偏置提供了方便理解的证实预测的理由，这个问题很快就被找到并修复。

同样，因为网络安全领域每个问题个体特性和对领域知识的要求较强，不像图像、文本等常见场景可以方便复用预训练模型，这也限制了深度神经网络迁移的用武之地。总的来说，深度学习作为机器学习的一个子类，它远不能让人随手一箭八百里外射下雄鹰，它的技术优势伴随着应用的局限，我们需要合理的使用该方法而不是盲目套用。

## 机器学习<<人工智能

《人工智能：一种现代方法》将“机器学习”放在第五单元，大家常说的“基于样本的学习”是该单元下第十九章（以 2019 年第四版为准）。人工智能作为学术领域方向，它还包括搜索、规划、逻辑、推理、知识表示、感知与行动等多方面，它在问题求解的应用方式应该是多个子方向的结合而不局限于机器学习。举例来说，AlphaGo 这个人工智能的标杆应用的成功来自于深度神经网络与蒙特卡洛树搜索方法（Monte Carlo tree search (MCTS)）的结合，而后者是每一本人工智能教材里介绍状态搜索都会提到的算法，而 AlphaGo 加入了深度网络的特征抽取与对抗训练，将 MCTS 算法的涉猎范畴从课本里的五子棋一举提高到了广大媒体欢呼的围棋。

机器学习之外的其他人工智能方法在网络安全领域问题也有不少例子。这里仍然有一个有趣的例子：攻击方试图利用 N 个漏洞及其组合试探目标的 K 个攻击点，每次必须使用 N 个漏洞中的 K 个测试，且漏洞利用的顺序与结果相关。在若干轮测试之后，攻击方只得到一些失败的组合以及其失败的原因，可能是挑选的 K 个漏洞部分已经失效（只知道个数但是很难知道哪一部分），可能是漏洞组合顺序不对等，我们能否根据已知测试结果设计更有效的漏洞组合设计新的测试策略？更难的问题是，是否可以设计根据上一轮结果做出调整的自动化的策略？这个问题可以通过状态空间搜索完成。如果将其简化，各位小朋友们会发现它和3位密码锁的谜题`*`很相似，从 0-9 十个数字里挑选三个数组成密码，从错误的密码中总结出规律，得到正确的密码。三位密码锁的问题（N=10，k=3）可以通过暴力搜索 000 到 999 的各种组合并验证其是否会掉进已知错误，但如果 N 很大，k 也较大的情况，我们必须使用上面提到的 MCTS 搜索并设计合理的剪枝条件（比如可能触发部分漏洞无效的漏洞组合等）减少搜索空间，可以引入主动学习（active learning）的办法按照提出的测试方法及其反馈调整搜索方向。这类问题统称为 MasterMind`*` 问题，感兴趣的小伙伴可以自行参考阅读。

在问题求解中，机器学习与非机器学习方法不应该互相排斥，而需要通力合作。基于样本的学习总会有由样本带来的局限性，它需要别的模型帮它“向其他地方看看”（look elsewhere）。在 NLP 中常见的例子就是实体消歧，例如智能体试图理解“苹果”这个单词，它需要知道这是水果还是那个电子产品公司，它的一般方法是通过上下文关联的知识库以图谱的形式推断“苹果”在语境中的意义。类似的方法在网络安全里也有不少结合了图模型与知识图谱的例子，比如本文作者团队去年发表的工作 “Honeypot + graph learning + reasoning = scale up your emerging threat analysis”`*` 就是结合了序列关键模型和知识图谱，它从发现两个不同 URL 在网络流量中的序列关联出发，通过构建知识图谱将 URL、二进制哈希值、对应的检测结果等上下文信息连接起来，再通过图模型中链接预测（link prediction）算法询问图谱是否能找到一条语义路径可以解释两个 URL 之间的关联，并利用了一阶逻辑（first order logic）的推理方法保证语义路径在充分但不必要和必要但不充分条件存在时的合理性，从而达到预测未知恶意软件下载途径的结果。

当然，本文不能包含人工智能方法下的各种子方法及其组合解决网络安全问题的方案，以上几个例子仅为抛砖引玉，更多的方法和组合方式留给各位小伙伴探索。

## 你是否考虑过其他办法？

Joshua Saxe 的推特上问过一个很好的问题，当我们展示基于机器学习模型的成果时，我们有没有考虑过更简单的办法？`*` 这些简单方法可以来自于理解领域知识并对其一般化表示，也可以来自于对数据的预处理，也可以对目标问题的认真理解与分拆等各个方面。

之前有某位小伙伴从课题研究中提出一个有意思的问题：在目标资产侦查阶段，攻击方通过子域名枚举爆破方法（subdomain enumeration），利用字典单词组合去猜测目标子域名，能不能通过收集其 DNS 流量并使用机器学习的办法破解其原始字典内容呢？在他尝试抄起 GPU 跳入 BERT 等深度模型之前，我建议不妨试试先把数据排序用相邻字串的最长公共子串猜测一个含有噪声的字典，再用这个字典去切分子域名，将字典问题变成字符串切分问题。随后的实验证明，这种更简单的算法不仅可以有效得到绝大部分字典，并且可以灵活对抗插入的噪声。

机器学习的优势是从数据中学习其统计表示，直观的认为是它拟合规则，但问题求解并不排斥由领域知识直接带来的规则，即使该规则只能部分的解决问题。例如 Alexa Rank 这个全球网站排名常被用来当作恶意软件 C&C 域名检测结果的参考，它包含的领域知识是”恶意软件不太可能利用高排名域名当作 C&C“。随着新的商业模式和攻防对抗，Alexa Rank 也被攻击方利用，本文作者和同事也通过 DNS 流量构建了更符合网络安全的域名信誉排名方法`*`，请有兴趣的小伙伴自行阅读。

更简单的方法也可来自于数据的筛选。正如好的食材只需要简单的烹饪即可迸发其香味，好的数据只需要简单的模型即可带来清晰的结果。一个有意思的例子来自于本文作者与前同事讨论他的文章 Asaf Nadler et al “Detection of Malicious and Low Throughput Data Exfiltration Over the DNS Protocol”`*` 在 DNS 数据流中检测低吞吐隧道这样常用在 APT 攻击中的数据渗出方法。因为低吞吐 DNS 隧道的信号很弱也很罕见，文中用独立森林（Isolation Forest）做异常检测需要细致的筛选特征，导致它在大规模有噪声的数据下很难表现其检测威力，也因为算力的问题限制了其解决问题的规模。我们在讨论中发现，如果在 DNS 数据流中对所有未见过的域名做一轮筛选并以此作为独立森林模型的输入，其预测表现和算力均可满足大规模数据流的要求。通过深入理解目标问题的场景，我们简单的调整了更合适的输入数据使得现有模型可以更上一层楼。

更简单的方法也可以来自于分拆目标问题，它可能是代表部分目标问题的子目标，也可以是目标问题的抽象降解（reduction）等，这些均遵循问题求解的一般方法，请有兴趣的小伙伴自行探索。一个有趣的例子是，本文作者与团队发表在 Botconf 工作 “Math + GPU + DNS = Cracking Locky Seeds in Real Time without Analyzing Samples”`*`，它在 DNS 数据流中检测 Locky 勒索软件的 DGA 域名，通过 GPU 暴力破解其 DGA 的种子并成功预测其未来域名。在这个工作中，我们将这一较难的问题分多步骤拆分和降解，并复用了之前工作中的异常模型和关联模型：

* Locky DGA 域名均为新域名，所以在 DNS 异常检测并筛选从未见过的域名
* Locky DGA 含有多个域名，所以我们通过 `domain2vec` 计算异常域名之间的序列关联而仅对较强关联的族群测试其 DGA 属性。
* Locky 通过伪随机数生成器生成单个长整数并以此输出域名字符串，所以我们将每个候选域名逆运算得到其对应的长整数，即可利用 GPU 批量爆破该整数在当前日期下可能对应的种子。

由此我们成功破解了 Locky DGA 的几十个随机数种子并将其反馈给研究社区。

本文作者建议数据科学团队在思考解决每个问题时可以反复提醒自己：

> 是否存在可以全部解决或者部分解决这个问题的其他办法？

## 总结与后记

在解决问题的过程中，我们必须坚持“问题求解”为主要目的，而相关的技术选型是支持该目的的方法，这些方法之间的合作应该大于竞争。这同时也要求数据科学团队不断的拓宽视野，多留意别的领域的成熟方法以及其为何有效的根本原因，并尝试引入网络安全领域。同时，本文作者也看到很多数据科学团队积极学习网络安全的领域知识，只有这样才能更有效的寻找适合该领域问题的技术。

本文作者收到了对这系列博客不少有意义的反馈和建议，各位小伙伴们也会从“机器学习为什么失败了”的话题出发，结合自己的工作和研究延伸了不少讨论。数据模型在网络安全领域是最近几年才出现较大规模的应用，工业界里的各种问题和困难也随之而来，这些问题的求解不像图像、语音、视频、文本等领域有较为成熟的方法框架，往往需要数据科学家从问题求解的基本方法出发，将数据模型知识结合网络安全的领域知识，寻找可以切入问题的方向，这其中难免有无数的失败，这都是符合现代科研方法的可预期的失败。我也相信通过多次失败的沮丧和偶然成功的惊喜，我们可以总结足够的经验教训，构建属于网络安全领域数据模型的一般方法框架，一起构建更加安全的互联网。

* Joshua Saxe with Hillary Sanders, Malware Data Science: Attack Detection and Attribution <https://nostarch.com/malwaredatascience>
* Mostafa Hassan, "Cracking Random Number Generators using Machine Learning – Part 1: xorshift128" <https://research.nccgroup.com/2021/10/15/cracking-random-number-generators-using-machine-learning-part-1-xorshift128/>
* Inductive Bias <https://en.wikipedia.org/wiki/Inductive_bias>
* Monte Carlo tree search <https://en.wikipedia.org/wiki/Monte_Carlo_tree_search>
* A step-by-step look at Alpha Zero and Monte Carlo Tree Search <https://joshvarty.github.io/AlphaZero/>
* 3 digit lock riddle: Using Prolog to solve a brain teaser (Master Mind) <https://stackoverflow.com/questions/61276283/using-prolog-to-solve-a-brain-teaser-master-mind>
* Mastermind <https://en.wikipedia.org/wiki/Mastermind_(board_game)>
* Joshua Saxe twitter <https://twitter.com/joshua_saxe/status/1328834273214861314>
* "System for Domain Reputation Scoring" Patent us 14/937699
* Asaf Nadler et al “Detection of Malicious and Low Throughput Data Exfiltration Over the DNS Protocol” <https://arxiv.org/pdf/1709.08395.pdf>
* “Math + GPU + DNS = Cracking Locky Seeds in Real Time without Analyzing Samples” <https://www.botconf.eu/2017/math-gpu-dns-cracking-locky-seeds-in-real-time-without-analyzing-samples/>
* "Honeypot + graph learning + reasoning = scale up your emerging threat analysis" <https://www.youtube.com/watch?v=r7KbGJPFkxQ&ab_channel=botconfeu>